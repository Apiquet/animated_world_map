{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated map which displays the protests locations in sequence\n",
    "With:\n",
    "- ##### <u> SQLDATE </u>\n",
    "- ##### <u> ActionGeo_Lat </u>\n",
    "- ##### <u> ActionGeo_Long </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "LEAFLET_PATH = 'Leaflet.MovingMarker-master\\\\animated_map\\\\'\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'C:\\\\Users\\\\antho\\\\Downloads\\\\ADAproj-02b470a29ee4.json'\n",
    "bigquery_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SQLDATE           3440495\n",
       "ActionGeo_Lat     3440495\n",
       "ActionGeo_Long    3440495\n",
       "EventCode         3440495\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching data from GDELT\n",
    "## BIG DATA, 3 000 000 rows\n",
    "\n",
    "if os.path.isfile(DATA_PATH + 'protests_location.csv') :\n",
    "    #If we already saved the data, don't run the query again, just get the data from the file saved previously\n",
    "    protests_df_location = pd.read_csv(DATA_PATH + 'protests_location.csv')\n",
    "else:\n",
    "    #query to get the date and the location of the protest events\n",
    "    #Remark: '14%' filters the protest events because they all start by '14'\n",
    "    query_protests_location = bigquery_client.query(\n",
    "        \"\"\"SELECT SQLDATE, ActionGeo_Lat, ActionGeo_Long, EventCode FROM `gdelt-bq.gdeltv2.events` \n",
    "        WHERE EventCode LIKE '14%' \"\"\")\n",
    "    protests_df_location = query_protests_location.result().to_dataframe()\n",
    "    # Write down a csv file\n",
    "    protests_df_location.to_csv(DATA_PATH + 'protests_location.csv', index=False)\n",
    "protests_df_location = protests_df_location.dropna()\n",
    "protests_df_location.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting ActionGeo_Lat and ActionGeo_Long\n",
    "protests_without_duplicated_values = protests_df_location\n",
    "#protests_without_duplicated_values['ActionGeo_Lat'] = protests_df_location['ActionGeo_Lat']\n",
    "#protests_without_duplicated_values['ActionGeo_Long'] = protests_df_location['ActionGeo_Long']\n",
    "\n",
    "#Removing duplicated values \n",
    "#The values are not really duplicated, they took place on different day\n",
    "#Plus, the localization of national protest is in the center of the country \n",
    "#We thus have a duplicated localizations when we have several national protests in the same country\n",
    "protests_without_duplicated_values=protests_without_duplicated_values.drop_duplicates(subset=['ActionGeo_Long', 'ActionGeo_Lat'], keep=False)\n",
    "protests_without_duplicated_values=protests_without_duplicated_values.sort_values('SQLDATE')\n",
    "protests_without_duplicated_values=protests_without_duplicated_values[protests_without_duplicated_values['SQLDATE']>=20140000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values, which use np.object_ dtype in pandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-03b20f21f49c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprotests_without_duplicated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EventCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mprotests_without_duplicated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EventCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprotests_without_duplicated_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EventCode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4366\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[0;32m   4367\u001b[0m                 name in self._accessors):\n\u001b[1;32m-> 4368\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1894\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1896\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py\u001b[0m in \u001b[0;36m_validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1915\u001b[0m             \u001b[1;31m# (instead of test for object dtype), but that isn't practical for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[1;31m# performance reasons until we have a str dtype (GH 9343)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m             raise AttributeError(\"Can only use .str accessor with string \"\n\u001b[0m\u001b[0;32m   1918\u001b[0m                                  \u001b[1;34m\"values, which use np.object_ dtype in \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m                                  \"pandas\")\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values, which use np.object_ dtype in pandas"
     ]
    }
   ],
   "source": [
    "protests_without_duplicated_values['EventCode']= protests_without_duplicated_values['EventCode'].str[0:3]\n",
    "protests_without_duplicated_values['EventCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protests_df_for_js = pd.DataFrame()\n",
    "protests_df_for_js[\"coord_for_js\"] = '[' + protests_without_duplicated_values['ActionGeo_Lat'].astype(str) + ',' + protests_without_duplicated_values['ActionGeo_Long'].astype(str) + '],'\n",
    "protests_df_for_js[\"dates\"] = protests_without_duplicated_values['SQLDATE'].astype(str)\n",
    "protests_df_for_js[\"dates\"] = '[' + protests_df_for_js['dates'].str[0:4] + protests_df_for_js['dates'].str[4:6] + protests_df_for_js['dates'].str[6:8] + '],'\n",
    "protests_df_for_js[\"event_code\"] = protests_without_duplicated_values['EventCode'].astype(str)\n",
    "protests_df_for_js[\"event_code\"] = '[' + protests_df_for_js['event_code'] + '],'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markers_number = 4\n",
    "markers_speed = 4000000 / markers_number\n",
    "\n",
    "protests_coordinates=\"\"\n",
    "protests_types=\"\"\n",
    "protests_dates=\"\"\n",
    "marker_declaration=\"\"\n",
    "string_addstation=\"\"\n",
    "\n",
    "for marker_idx in range(1,markers_number+1):\n",
    "    protests_coordinates = protests_coordinates + \"\\n var protests_coordinates\" + str(marker_idx) + \" = [\"\n",
    "    protests_dates = protests_dates + \"\\n var protests_dates\" + str(marker_idx) + \" = [\"\n",
    "    protests_types = protests_types + \"\\n var protests_types\" + str(marker_idx) + \" = [\"\n",
    "    addstation_idx = 0\n",
    "    i = 0\n",
    "    for idx in range(marker_idx,len(protests_df_for_js),markers_number):\n",
    "        i=i+1\n",
    "        protests_coordinates = protests_coordinates + protests_df_for_js[\"coord_for_js\"].iloc[idx]\n",
    "        protests_dates = protests_dates + protests_df_for_js[\"dates\"].iloc[idx]\n",
    "        protests_types = protests_types + protests_df_for_js[\"event_code\"].iloc[idx]\n",
    "        if addstation_idx == 0 :\n",
    "                addstation_idx = 1\n",
    "                string_addstation = string_addstation + \"\\n\"\n",
    "        string_addstation = string_addstation + \"marker\" + str(marker_idx) + \".addStation(\" + str(i) + \", 500);\"\n",
    "    \n",
    "    #protests_df_for_js=protests_df_for_js.iloc[number_of_protests_per_loop:]\n",
    "    protests_coordinates = protests_coordinates[:-1]\n",
    "    protests_coordinates = protests_coordinates + \"]\"\n",
    "    protests_dates = protests_dates[:-1]\n",
    "    protests_dates = protests_dates + \"]\"  \n",
    "    protests_types = protests_types[:-1]\n",
    "    protests_types = protests_types + \"]\"        \n",
    "\n",
    "    marker_declaration = marker_declaration + \"\\n var marker\" + str(marker_idx) + \" = L.Marker.movingMarker(protests_coordinates\" + str(marker_idx) + \",protests_dates1,protests_types\" + str(marker_idx) +\",\" + str(markers_speed) + \", {autostart: true}).addTo(map);\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readFile = open(LEAFLET_PATH + \"script_origin.js\")\n",
    "\n",
    "lines = readFile.readlines()\n",
    "lines = lines[:-1]\n",
    "readFile.close()\n",
    "\n",
    "lines.append(protests_coordinates+'\\n')\n",
    "lines.append(protests_dates+'\\n')\n",
    "lines.append(protests_types+'\\n')\n",
    "lines.append(marker_declaration+'\\n')\n",
    "lines.append(string_addstation+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open(LEAFLET_PATH + \"script.js\",'w')\n",
    "\n",
    "w.writelines([item for item in lines])\n",
    "\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<h1><a href='\"+LEAFLET_PATH+\"index.html' target='_blank'>Animated map that displays protests location in sequence (Ctrl+Click)</a></h1>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
